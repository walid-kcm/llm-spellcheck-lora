{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":3167333,"sourceType":"datasetVersion","datasetId":1887500}],"dockerImageVersionId":31236,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# LoRA Fine-tuning (4-bit) ‚Äî Spelling Correction (Kaggle 2√óT4)\n\nThis notebook was run on **Kaggle** using **2√ó NVIDIA T4 GPUs** (accelerator) to fine-tune a small instruction-tuned LLM with **LoRA** + **4-bit quantization**.\n\nPipeline: **data ‚Üí prompt formatting (loss masking) ‚Üí training ‚Üí eval (EM/CER) ‚Üí inference ‚Üí save adapter**\n","metadata":{}},{"cell_type":"code","source":"%%capture\nimport os\n\n!pip install pip3-autoremove\n!pip install torch torchvision torchaudio xformers --index-url https://download.pytorch.org/whl/cu128\n!pip install unsloth\n!pip install transformers==4.56.2\n!pip install --no-deps trl==0.22.2","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-01-28T18:22:31.446047Z","iopub.execute_input":"2026-01-28T18:22:31.446295Z","iopub.status.idle":"2026-01-28T18:23:20.475137Z","shell.execute_reply.started":"2026-01-28T18:22:31.446273Z","shell.execute_reply":"2026-01-28T18:23:20.474310Z"}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"## Model loading (4-bit) + LoRA adapters\n\nLoad the base model in 4-bit and attach LoRA adapters for efficient fine-tuning.","metadata":{}},{"cell_type":"code","source":"from unsloth import FastLanguageModel\nimport torch\nmax_seq_length = 4096 # Choose any! We auto support RoPE Scaling internally!\ndtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\nload_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False.\n\n# 4bit pre quantized models we support for 4x faster downloading + no OOMs.\nfourbit_models = [\n    \"unsloth/mistral-7b-bnb-4bit\",\n    \"unsloth/mistral-7b-instruct-v0.2-bnb-4bit\",\n    \"unsloth/llama-2-7b-bnb-4bit\",\n    \"unsloth/llama-2-13b-bnb-4bit\",\n    \"unsloth/codellama-34b-bnb-4bit\",\n    \"unsloth/tinyllama-bnb-4bit\",\n    \"unsloth/gemma-7b-bnb-4bit\", # New Google 6 trillion tokens model 2.5x faster!\n    \"unsloth/gemma-2b-bnb-4bit\",\n] # More models at https://huggingface.co/unsloth\n\nmodel, tokenizer = FastLanguageModel.from_pretrained(\n    model_name = \"Doctor-Shotgun/TinyLlama-1.1B-32k-Instruct\", # \"unsloth/tinyllama\" for 16bit loading\n    max_seq_length = max_seq_length,\n    dtype = dtype,\n    load_in_4bit = load_in_4bit,\n    # token = \"hf_...\", # use one if using gated models like meta-llama/Llama-2-7b-hf\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-28T18:23:20.477118Z","iopub.execute_input":"2026-01-28T18:23:20.477394Z","iopub.status.idle":"2026-01-28T18:24:25.918421Z","shell.execute_reply.started":"2026-01-28T18:23:20.477366Z","shell.execute_reply":"2026-01-28T18:24:25.917700Z"}},"outputs":[{"name":"stdout","text":"ü¶• Unsloth: Will patch your computer to enable 2x faster free finetuning.\n","output_type":"stream"},{"name":"stderr","text":"2026-01-28 18:23:31.781887: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1769624612.163335      55 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1769624612.271217      55 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nW0000 00:00:1769624613.049497      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1769624613.049539      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1769624613.049542      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1769624613.049544      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","output_type":"stream"},{"name":"stdout","text":"ü¶• Unsloth Zoo will now patch everything to make training faster!\nUnsloth: Could not import trl.trainer.alignprop_trainer: Failed to import trl.trainer.alignprop_trainer because of the following error (look up to see its traceback):\nFailed to import trl.models.modeling_sd_base because of the following error (look up to see its traceback):\nFailed to import diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion because of the following error (look up to see its traceback):\nFailed to import diffusers.loaders.ip_adapter because of the following error (look up to see its traceback):\n/usr/local/lib/python3.12/dist-packages/xformers/flash_attn_3/_C.so: undefined symbol: _ZNK3c106SymInt22maybe_as_int_slow_pathEv\nUnsloth: Could not import trl.trainer.ddpo_trainer: Failed to import trl.trainer.ddpo_trainer because of the following error (look up to see its traceback):\nFailed to import trl.models.modeling_sd_base because of the following error (look up to see its traceback):\nFailed to import diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion because of the following error (look up to see its traceback):\nFailed to import diffusers.loaders.ip_adapter because of the following error (look up to see its traceback):\n/usr/local/lib/python3.12/dist-packages/xformers/flash_attn_3/_C.so: undefined symbol: _ZNK3c106SymInt22maybe_as_int_slow_pathEv\n==((====))==  Unsloth 2026.1.4: Fast Llama patching. Transformers: 4.56.2.\n   \\\\   /|    Tesla T4. Num GPUs = 2. Max memory: 14.741 GB. Platform: Linux.\nO^O/ \\_/ \\    Torch: 2.8.0+cu126. CUDA: 7.5. CUDA Toolkit: 12.6. Triton: 3.4.0\n\\        /    Bfloat16 = FALSE. FA [Xformers = None. FA2 = False]\n \"-____-\"     Free license: http://github.com/unslothai/unsloth\nUnsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/2.20G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fdb1ac46188240f9833af3887774e969"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/129 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"70955f02251b4d3495dbaaa9d7b79cef"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"40b0d1649e724bb5956ac455e9ae0d8e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"068e0012c03046a196c55e8617cc635b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/551 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"752b7359cea64c26b16cecccd9f8441e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9ea6b19aa33a4fc6b6c8034a0b273eba"}},"metadata":{}},{"name":"stdout","text":"Doctor-Shotgun/TinyLlama-1.1B-32k-Instruct does not have a padding token! Will use pad_token = <unk>.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"model = FastLanguageModel.get_peft_model(\n    model,\n    r = 32, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n    lora_alpha = 32,\n    lora_dropout = 0, # Currently only supports dropout = 0\n    bias = \"none\",    # Currently only supports bias = \"none\"\n    use_gradient_checkpointing = False, # @@@ IF YOU GET OUT OF MEMORY - set to True @@@\n    random_state = 3407,\n    use_rslora = False,  # We support rank stabilized LoRA\n    loftq_config = None, # And LoftQ\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-28T18:24:25.919350Z","iopub.execute_input":"2026-01-28T18:24:25.919644Z","iopub.status.idle":"2026-01-28T18:24:29.553615Z","shell.execute_reply.started":"2026-01-28T18:24:25.919596Z","shell.execute_reply":"2026-01-28T18:24:29.552825Z"}},"outputs":[{"name":"stderr","text":"Unsloth 2026.1.4 patched 22 layers with 22 QKV layers, 22 O layers and 22 MLP layers.\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"## Prompt formatting\n\nWe convert each example into an instruction-style prompt:\nInstruction + Input ‚Üí Response (target).\n","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nfrom datasets import Dataset\n\ndf_train = pd.read_csv(\"/kaggle/input/spelling-mistake-data-1mn/train.csv\")\ndf_val   = pd.read_csv(\"/kaggle/input/spelling-mistake-data-1mn/val.csv\")\n\n\nINSTRUCTION = (\n    \"Correct only spelling mistakes in the sentence. \"\n    \"Do not change the meaning, do not add/remove words unless required to fix spelling. \"\n    \"Return ONLY the corrected sentence, nothing else.\"\n)\n\n\ndef prepare_df(df):\n    df = df.rename(columns={\"augmented_text\": \"input\", \"text\": \"output\"})\n    df[\"instruction\"] = INSTRUCTION\n    return df[[\"instruction\", \"input\", \"output\"]]\n\ntrain_df = prepare_df(df_train)\nval_df   = prepare_df(df_val)\n\ntrain_dataset = Dataset.from_pandas(train_df).select(range(15000))\nval_dataset   = Dataset.from_pandas(val_df).select(range(2000))\n\n\nalpaca_prompt = \"\"\"### Instruction:\n{instruction}\n\n### Input:\n{input}\n\n### Response:\n{output}\"\"\" + tokenizer.eos_token\n\n\ndef build_text(examples):\n    texts = []\n    for instr, inp, out in zip(examples[\"instruction\"], examples[\"input\"], examples[\"output\"]):\n        texts.append(alpaca_prompt.format(instruction=instr, input=inp, output=out))\n    return {\"text\": texts}\n\ntrain_dataset = train_dataset.map(build_text, batched=True)\nval_dataset   = val_dataset.map(build_text, batched=True)\n\nprint(\"EXEMPLE TEXT:\\n\", train_dataset[0][\"text\"][:500])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-23T13:19:09.796690Z","iopub.execute_input":"2026-01-23T13:19:09.797428Z","iopub.status.idle":"2026-01-23T13:19:13.274789Z","shell.execute_reply.started":"2026-01-23T13:19:09.797385Z","shell.execute_reply":"2026-01-23T13:19:13.273991Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/15000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f186f4b1fa67488f8cf4915263ccb388"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a88528b11b544d39b301b8e5fedb8b26"}},"metadata":{}},{"name":"stdout","text":"EXEMPLE TEXT:\n ### Instruction:\nCorrect only spelling mistakes in the sentence. Do not change the meaning, do not add/remove words unless required to fix spelling. Return ONLY the corrected sentence, nothing else.\n\n### Input:\nbarbaric and shocking use of ofcre agaistn\n\n### Response:\nbarbaric and shocking use of force against</s>\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"## Loss masking (train only on the answer)\n\nWe mask labels before `### Response:` so the loss is computed only on the corrected sentence.\n","metadata":{}},{"cell_type":"code","source":"response_marker = \"\\n\\n### Response:\\n\"   \n\nmarker_ids = tokenizer(response_marker, add_special_tokens=False)[\"input_ids\"]\n\ndef find_subseq(seq, sub):\n    for i in range(len(seq) - len(sub) + 1):\n        if seq[i:i+len(sub)] == sub:\n            return i\n    return -1\n\ndef show_example(ds, n=160):\n    ex = ds[0]\n    input_ids = ex[\"input_ids\"]\n    labels    = ex[\"labels\"]\n    toks = tokenizer.convert_ids_to_tokens(input_ids)\n\n    print(\"idx | token                  | id     | label   | learn?\")\n    print(\"-\"*70)\n    for i, (t, tid, lab) in enumerate(zip(toks, input_ids, labels)):\n        if i >= n: break\n        learn = \"LEARN\" if lab != -100 else \"IGN\"\n        print(f\"{i:3d} | {t[:22]:22s} | {tid:6d} | {lab:6d} | {learn}\")\n\n\nMARKER = \"### Response:\\n\"\n\ndef tokenize_and_mask(example):\n    text = example[\"text\"]\n    idx = text.find(MARKER)\n\n    enc = tokenizer(text, truncation=True, max_length=max_seq_length)\n    labels = enc[\"input_ids\"].copy()\n\n    if idx == -1:\n        enc[\"labels\"] = [-100] * len(labels)\n        return enc\n\n    prefix_text = text[: idx + len(MARKER)]\n    prefix_ids = tokenizer(prefix_text, truncation=True, max_length=max_seq_length)[\"input_ids\"]\n    start = len(prefix_ids)\n\n    if start >= len(labels):\n        enc[\"labels\"] = [-100] * len(labels)\n        return enc\n\n    for i in range(start):\n        labels[i] = -100\n\n    enc[\"labels\"] = labels\n    return enc\n\n\ntrain_tok = train_dataset.map(tokenize_and_mask, remove_columns=train_dataset.column_names, num_proc=8)\nval_tok   = val_dataset.map(tokenize_and_mask, remove_columns=val_dataset.column_names, num_proc=8)\nshow_example(train_tok, n=200)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-23T13:19:13.275996Z","iopub.execute_input":"2026-01-23T13:19:13.276361Z","iopub.status.idle":"2026-01-23T13:19:18.891138Z","shell.execute_reply.started":"2026-01-23T13:19:13.276332Z","shell.execute_reply":"2026-01-23T13:19:18.890444Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map (num_proc=8):   0%|          | 0/15000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fe8c4efd9b21415b83cbbb392a16bdd9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map (num_proc=8):   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"23cbe5379ac64284aee46c6fa55e2641"}},"metadata":{}},{"name":"stdout","text":"idx | token                  | id     | label   | learn?\n----------------------------------------------------------------------\n  0 | <s>                    |      1 |   -100 | IGN\n  1 | ‚ñÅ###                   |    835 |   -100 | IGN\n  2 | ‚ñÅInst                  |   2799 |   -100 | IGN\n  3 | ruction                |   4080 |   -100 | IGN\n  4 | :                      |  29901 |   -100 | IGN\n  5 | <0x0A>                 |     13 |   -100 | IGN\n  6 | Cor                    |  12521 |   -100 | IGN\n  7 | rect                   |   1621 |   -100 | IGN\n  8 | ‚ñÅonly                  |    871 |   -100 | IGN\n  9 | ‚ñÅsp                    |    805 |   -100 | IGN\n 10 | elling                 |   7807 |   -100 | IGN\n 11 | ‚ñÅmistakes              |  28947 |   -100 | IGN\n 12 | ‚ñÅin                    |    297 |   -100 | IGN\n 13 | ‚ñÅthe                   |    278 |   -100 | IGN\n 14 | ‚ñÅsentence              |  10541 |   -100 | IGN\n 15 | .                      |  29889 |   -100 | IGN\n 16 | ‚ñÅDo                    |   1938 |   -100 | IGN\n 17 | ‚ñÅnot                   |    451 |   -100 | IGN\n 18 | ‚ñÅchange                |   1735 |   -100 | IGN\n 19 | ‚ñÅthe                   |    278 |   -100 | IGN\n 20 | ‚ñÅmeaning               |   6593 |   -100 | IGN\n 21 | ,                      |  29892 |   -100 | IGN\n 22 | ‚ñÅdo                    |    437 |   -100 | IGN\n 23 | ‚ñÅnot                   |    451 |   -100 | IGN\n 24 | ‚ñÅadd                   |    788 |   -100 | IGN\n 25 | /                      |  29914 |   -100 | IGN\n 26 | remove                 |   5992 |   -100 | IGN\n 27 | ‚ñÅwords                 |   3838 |   -100 | IGN\n 28 | ‚ñÅunless                |   6521 |   -100 | IGN\n 29 | ‚ñÅrequired              |   3734 |   -100 | IGN\n 30 | ‚ñÅto                    |    304 |   -100 | IGN\n 31 | ‚ñÅfix                   |   2329 |   -100 | IGN\n 32 | ‚ñÅsp                    |    805 |   -100 | IGN\n 33 | elling                 |   7807 |   -100 | IGN\n 34 | .                      |  29889 |   -100 | IGN\n 35 | ‚ñÅReturn                |   7106 |   -100 | IGN\n 36 | ‚ñÅON                    |   6732 |   -100 | IGN\n 37 | LY                     |  16786 |   -100 | IGN\n 38 | ‚ñÅthe                   |    278 |   -100 | IGN\n 39 | ‚ñÅcorrected             |  24114 |   -100 | IGN\n 40 | ‚ñÅsentence              |  10541 |   -100 | IGN\n 41 | ,                      |  29892 |   -100 | IGN\n 42 | ‚ñÅnothing               |   3078 |   -100 | IGN\n 43 | ‚ñÅelse                  |   1683 |   -100 | IGN\n 44 | .                      |  29889 |   -100 | IGN\n 45 | <0x0A>                 |     13 |   -100 | IGN\n 46 | <0x0A>                 |     13 |   -100 | IGN\n 47 | ##                     |   2277 |   -100 | IGN\n 48 | #                      |  29937 |   -100 | IGN\n 49 | ‚ñÅInput                 |  10567 |   -100 | IGN\n 50 | :                      |  29901 |   -100 | IGN\n 51 | <0x0A>                 |     13 |   -100 | IGN\n 52 | bar                    |   1646 |   -100 | IGN\n 53 | bar                    |   1646 |   -100 | IGN\n 54 | ic                     |    293 |   -100 | IGN\n 55 | ‚ñÅand                   |    322 |   -100 | IGN\n 56 | ‚ñÅshock                 |  19253 |   -100 | IGN\n 57 | ing                    |    292 |   -100 | IGN\n 58 | ‚ñÅuse                   |    671 |   -100 | IGN\n 59 | ‚ñÅof                    |    310 |   -100 | IGN\n 60 | ‚ñÅof                    |    310 |   -100 | IGN\n 61 | cre                    |   1037 |   -100 | IGN\n 62 | ‚ñÅag                    |    946 |   -100 | IGN\n 63 | a                      |  29874 |   -100 | IGN\n 64 | ist                    |    391 |   -100 | IGN\n 65 | n                      |  29876 |   -100 | IGN\n 66 | <0x0A>                 |     13 |   -100 | IGN\n 67 | <0x0A>                 |     13 |   -100 | IGN\n 68 | ##                     |   2277 |   -100 | IGN\n 69 | #                      |  29937 |   -100 | IGN\n 70 | ‚ñÅResponse              |  13291 |   -100 | IGN\n 71 | :                      |  29901 |   -100 | IGN\n 72 | <0x0A>                 |     13 |   -100 | IGN\n 73 | bar                    |   1646 |   1646 | LEARN\n 74 | bar                    |   1646 |   1646 | LEARN\n 75 | ic                     |    293 |    293 | LEARN\n 76 | ‚ñÅand                   |    322 |    322 | LEARN\n 77 | ‚ñÅshock                 |  19253 |  19253 | LEARN\n 78 | ing                    |    292 |    292 | LEARN\n 79 | ‚ñÅuse                   |    671 |    671 | LEARN\n 80 | ‚ñÅof                    |    310 |    310 | LEARN\n 81 | ‚ñÅforce                 |   4889 |   4889 | LEARN\n 82 | ‚ñÅagainst               |   2750 |   2750 | LEARN\n 83 | </s>                   |      2 |      2 | LEARN\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"def learns(ex): \n    return any(l != -100 for l in ex[\"labels\"])\n\nprint(\"ex0 learns?\", learns(train_tok[0]))\nprint(\"ratio learns =\", sum(learns(ex) for ex in train_tok) / len(train_tok))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-23T13:19:18.892215Z","iopub.execute_input":"2026-01-23T13:19:18.892512Z","iopub.status.idle":"2026-01-23T13:19:21.003583Z","shell.execute_reply.started":"2026-01-23T13:19:18.892477Z","shell.execute_reply":"2026-01-23T13:19:21.002928Z"}},"outputs":[{"name":"stdout","text":"ex0 learns? True\nratio learns = 1.0\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"## Training\n\nDefine padding/collator + training config, then fine-tune with HF Trainer.\n","metadata":{}},{"cell_type":"code","source":"from transformers import TrainingArguments, Trainer, DataCollatorForSeq2Seq\n\n# Important : beaucoup de tokenizers Llama n'ont pas de pad_token\nif tokenizer.pad_token is None:\n    tokenizer.pad_token = tokenizer.eos_token\n\n# Pour √©viter un warning/perf issue en training\nmodel.config.use_cache = False\n\ncollator = DataCollatorForSeq2Seq(\n    tokenizer=tokenizer,\n    padding=True,\n    label_pad_token_id=-100,\n    return_tensors=\"pt\",\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-23T13:19:21.004470Z","iopub.execute_input":"2026-01-23T13:19:21.004782Z","iopub.status.idle":"2026-01-23T13:19:21.009297Z","shell.execute_reply.started":"2026-01-23T13:19:21.004735Z","shell.execute_reply":"2026-01-23T13:19:21.008539Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"args = TrainingArguments(\n    output_dir=\"out\",\n    per_device_train_batch_size=2,\n    per_device_eval_batch_size=2,\n    gradient_accumulation_steps=8,   # batch effectif = 16\n    learning_rate=1e-4,\n    num_train_epochs=5,\n    fp16=True,                       # T4\n    logging_steps=20,\n    eval_strategy=\"steps\",\n    eval_steps=200,\n    save_strategy=\"steps\",\n    save_steps=200,\n    save_total_limit=2,\n    report_to=\"none\",\n)\n\ntrainer = Trainer(\n    model=model,\n    args=args,\n    train_dataset=train_tok,\n    eval_dataset=val_tok,\n    data_collator=collator,\n)\n\ntrainer.train()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-23T13:19:21.010279Z","iopub.execute_input":"2026-01-23T13:19:21.010577Z","iopub.status.idle":"2026-01-23T14:28:55.682148Z","shell.execute_reply.started":"2026-01-23T13:19:21.010527Z","shell.execute_reply":"2026-01-23T14:28:55.681528Z"},"jupyter":{"source_hidden":true}},"outputs":[{"name":"stderr","text":"==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n   \\\\   /|    Num examples = 15,000 | Num Epochs = 5 | Total steps = 2,345\nO^O/ \\_/ \\    Batch size per device = 4 | Gradient accumulation steps = 8\n\\        /    Data Parallel GPUs = 1 | Total batch size (4 x 8 x 1) = 32\n \"-____-\"     Trainable parameters = 25,231,360 of 1,125,279,744 (2.24% trained)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='2345' max='2345' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [2345/2345 1:09:29, Epoch 5/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>200</td>\n      <td>0.735300</td>\n      <td>0.711645</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>0.649900</td>\n      <td>0.624885</td>\n    </tr>\n    <tr>\n      <td>600</td>\n      <td>0.552800</td>\n      <td>0.581439</td>\n    </tr>\n    <tr>\n      <td>800</td>\n      <td>0.542500</td>\n      <td>0.553835</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>0.474800</td>\n      <td>0.537374</td>\n    </tr>\n    <tr>\n      <td>1200</td>\n      <td>0.476400</td>\n      <td>0.521951</td>\n    </tr>\n    <tr>\n      <td>1400</td>\n      <td>0.471500</td>\n      <td>0.507718</td>\n    </tr>\n    <tr>\n      <td>1600</td>\n      <td>0.428800</td>\n      <td>0.502575</td>\n    </tr>\n    <tr>\n      <td>1800</td>\n      <td>0.440700</td>\n      <td>0.497645</td>\n    </tr>\n    <tr>\n      <td>2000</td>\n      <td>0.372700</td>\n      <td>0.497331</td>\n    </tr>\n    <tr>\n      <td>2200</td>\n      <td>0.394000</td>\n      <td>0.493598</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"Unsloth: Not an error, but LlamaForCausalLM does not accept `num_items_in_batch`.\nUsing gradient accumulation will be very slightly less accurate.\nRead more on gradient accumulation issues here: https://unsloth.ai/blog/gradient\n","output_type":"stream"},{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=2345, training_loss=0.5195235861389876, metrics={'train_runtime': 4172.6677, 'train_samples_per_second': 17.974, 'train_steps_per_second': 0.562, 'total_flos': 4.421501847286579e+16, 'train_loss': 0.5195235861389876, 'epoch': 5.0})"},"metadata":{}}],"execution_count":8},{"cell_type":"markdown","source":"## Save LoRA adapter\n\nSave the adapter weights (and tokenizer) for later inference without retraining.\n","metadata":{}},{"cell_type":"code","source":"model.save_pretrained(\"lora_adapter\")\ntokenizer.save_pretrained(\"lora_adapter\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-23T14:28:55.683242Z","iopub.execute_input":"2026-01-23T14:28:55.683851Z","iopub.status.idle":"2026-01-23T14:28:56.070895Z","shell.execute_reply.started":"2026-01-23T14:28:55.683821Z","shell.execute_reply":"2026-01-23T14:28:56.070266Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"('lora_adapter/tokenizer_config.json',\n 'lora_adapter/special_tokens_map.json',\n 'lora_adapter/chat_template.jinja',\n 'lora_adapter/tokenizer.model',\n 'lora_adapter/added_tokens.json',\n 'lora_adapter/tokenizer.json')"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"from unsloth import FastLanguageModel\nFastLanguageModel.for_inference(model)\n\ndef make_prompt(sentence):\n    return f\"\"\"### Instruction:\n{INSTRUCTION}\n\n### Input:\n{sentence}\n\n### Response:\n\"\"\"\n\ntest_sentence = \"bar bar ic and shocking use of creag aistn\"\ninputs = tokenizer([make_prompt(test_sentence)], return_tensors=\"pt\").to(\"cuda\")\n\nout = model.generate(\n    **inputs,\n    max_new_tokens=64,\n    do_sample=False,\n)\nprint(tokenizer.decode(out[0], skip_special_tokens=True))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-23T14:28:56.071997Z","iopub.execute_input":"2026-01-23T14:28:56.072356Z","iopub.status.idle":"2026-01-23T14:28:56.787844Z","shell.execute_reply.started":"2026-01-23T14:28:56.072325Z","shell.execute_reply":"2026-01-23T14:28:56.787058Z"}},"outputs":[{"name":"stdout","text":"### Instruction:\nCorrect only spelling mistakes in the sentence. Do not change the meaning, do not add/remove words unless required to fix spelling. Return ONLY the corrected sentence, nothing else.\n\n### Input:\nbar bar ic and shocking use of creag aistn\n\n### Response:\nbar bar ic and shocking use of crapistan\n","output_type":"stream"}],"execution_count":10},{"cell_type":"markdown","source":"## Evaluation (Base vs Fine-tuned)\n\nCompute Exact Match (EM) and Character Error Rate (CER), then inspect a few predictions.\n","metadata":{}},{"cell_type":"code","source":"df_test = pd.read_csv(\"/kaggle/input/spelling-mistake-data-1mn/test.csv\")\ntest_df = prepare_df(df_test)\n\ntest_dataset = Dataset.from_pandas(test_df).select(range(1000))  # optionnel pour tester vite\ntest_dataset = test_dataset.map(build_text, batched=True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-23T14:28:56.788828Z","iopub.execute_input":"2026-01-23T14:28:56.789165Z","iopub.status.idle":"2026-01-23T14:28:57.166034Z","shell.execute_reply.started":"2026-01-23T14:28:56.789108Z","shell.execute_reply":"2026-01-23T14:28:57.165185Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f87e9c374e8a4ef091eb0f025e8ed786"}},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"def build_prompt(instr, inp):\n    return f\"\"\"### Instruction:\n{instr}\n\n### Input:\n{inp}\n\n### Response:\n\"\"\"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-23T14:28:57.167656Z","iopub.execute_input":"2026-01-23T14:28:57.167898Z","iopub.status.idle":"2026-01-23T14:28:57.171490Z","shell.execute_reply.started":"2026-01-23T14:28:57.167870Z","shell.execute_reply":"2026-01-23T14:28:57.170803Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"from unsloth import FastLanguageModel\nFastLanguageModel.for_inference(model)\n\n@torch.no_grad()\ndef generate_batch(model, tokenizer, batch_prompts, max_new_tokens=64):\n    inputs = tokenizer(batch_prompts, return_tensors=\"pt\", padding=True, truncation=True).to(\"cuda\")\n    out = model.generate(**inputs, max_new_tokens=max_new_tokens, do_sample=False)\n    decoded = tokenizer.batch_decode(out, skip_special_tokens=True)\n\n    # On r√©cup√®re seulement ce qui est apr√®s \"### Response:\"\n    preds = []\n    for full in decoded:\n        if \"### Response:\" in full:\n            preds.append(full.split(\"### Response:\")[-1].strip())\n        else:\n            preds.append(full.strip())\n    return preds\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-23T14:28:57.172500Z","iopub.execute_input":"2026-01-23T14:28:57.172783Z","iopub.status.idle":"2026-01-23T14:28:57.196669Z","shell.execute_reply.started":"2026-01-23T14:28:57.172757Z","shell.execute_reply":"2026-01-23T14:28:57.195932Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"def exact_match(pred, ref):\n    return int(pred.strip() == ref.strip())\n\ndef levenshtein(a, b):\n    a, b = a.strip(), b.strip()\n    n, m = len(a), len(b)\n    dp = list(range(m+1))\n    for i in range(1, n+1):\n        prev = dp[0]\n        dp[0] = i\n        for j in range(1, m+1):\n            cur = dp[j]\n            cost = 0 if a[i-1] == b[j-1] else 1\n            dp[j] = min(dp[j] + 1, dp[j-1] + 1, prev + cost)\n            prev = cur\n    return dp[m]\n\ndef cer(pred, ref):\n    ref = ref.strip()\n    if len(ref) == 0:\n        return 0.0 if pred.strip() == \"\" else 1.0\n    return levenshtein(pred, ref) / len(ref)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-23T14:28:57.197566Z","iopub.execute_input":"2026-01-23T14:28:57.197939Z","iopub.status.idle":"2026-01-23T14:28:57.213822Z","shell.execute_reply.started":"2026-01-23T14:28:57.197894Z","shell.execute_reply":"2026-01-23T14:28:57.213281Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"# build prompts + refs\nN = 500  # ajuste\ninstrs = test_dataset[\"instruction\"][:N]\ninps   = test_dataset[\"input\"][:N]\nrefs   = test_dataset[\"output\"][:N]\n\nprompts = [build_prompt(i, x) for i, x in zip(instrs, inps)]\n\npreds = generate_batch(model, tokenizer, prompts, max_new_tokens=64)\n\nem  = sum(exact_match(p, r) for p, r in zip(preds, refs)) / N\ncer_mean = sum(cer(p, r) for p, r in zip(preds, refs)) / N\n\nprint(\"Exact match:\", em)\nprint(\"CER:\", cer_mean)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-23T14:28:57.214782Z","iopub.execute_input":"2026-01-23T14:28:57.215361Z","iopub.status.idle":"2026-01-23T14:29:35.467857Z","shell.execute_reply.started":"2026-01-23T14:28:57.215327Z","shell.execute_reply":"2026-01-23T14:29:35.466931Z"}},"outputs":[{"name":"stdout","text":"Exact match: 0.256\nCER: 0.11135630819087414\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"import re\nimport torch\nfrom unsloth import FastLanguageModel\n\n# --- Helpers: extraction + normalisation ---\ndef extract_response(full_text: str) -> str:\n    # r√©cup√®re ce qui suit le dernier \"### Response:\"\n    if \"### Response:\" in full_text:\n        ans = full_text.split(\"### Response:\")[-1]\n    else:\n        ans = full_text\n    # coupe si le mod√®le r√©-imprime une nouvelle section\n    if \"\\n### \" in ans:\n        ans = ans.split(\"\\n### \")[0]\n    return ans.strip()\n\n_ws = re.compile(r\"\\s+\")\ndef normalize(s: str) -> str:\n    return _ws.sub(\" \", s).strip()\n\n@torch.no_grad()\ndef generate_all(model, tokenizer, prompts, batch_size=4, max_new_tokens=64):\n    FastLanguageModel.for_inference(model)\n    preds = []\n    for i in range(0, len(prompts), batch_size):\n        batch = prompts[i:i+batch_size]\n        inputs = tokenizer(batch, return_tensors=\"pt\", padding=True, truncation=True).to(\"cuda\")\n        out = model.generate(\n            **inputs,\n            max_new_tokens=max_new_tokens,\n            do_sample=False,\n            pad_token_id=tokenizer.pad_token_id,\n            eos_token_id=tokenizer.eos_token_id,\n        )\n        decoded = tokenizer.batch_decode(out, skip_special_tokens=True)\n        preds.extend([extract_response(t) for t in decoded])\n    return preds\n\ndef exact_match(pred, ref):\n    return int(normalize(pred) == normalize(ref))\n\ndef levenshtein(a, b):\n    a, b = a.strip(), b.strip()\n    n, m = len(a), len(b)\n    dp = list(range(m+1))\n    for i in range(1, n+1):\n        prev = dp[0]\n        dp[0] = i\n        for j in range(1, m+1):\n            cur = dp[j]\n            cost = 0 if a[i-1] == b[j-1] else 1\n            dp[j] = min(dp[j] + 1, dp[j-1] + 1, prev + cost)\n            prev = cur\n    return dp[m]\n\ndef cer(pred, ref):\n    pred, ref = normalize(pred), normalize(ref)\n    if len(ref) == 0:\n        return 0.0 if pred == \"\" else 1.0\n    return levenshtein(pred, ref) / len(ref)\n\ndef score(preds, refs):\n    N = len(refs)\n    em = sum(exact_match(p, r) for p, r in zip(preds, refs)) / N\n    cer_mean = sum(cer(p, r) for p, r in zip(preds, refs)) / N\n    return em, cer_mean\n\n# --- 1) Eval RAW model (base, sans LoRA) ---\nraw_model, _ = FastLanguageModel.from_pretrained(\n    model_name=\"Doctor-Shotgun/TinyLlama-1.1B-32k-Instruct\",\n    max_seq_length=max_seq_length,\n    dtype=None,\n    load_in_4bit=True,\n)\n\nraw_preds = generate_all(raw_model, tokenizer, prompts, batch_size=4, max_new_tokens=64)\nraw_em, raw_cer = score(raw_preds, refs)\n\n# lib√®re VRAM du raw\ndel raw_model\ntorch.cuda.empty_cache()\n\n# --- 2) Eval Fine-tuned model (ton 'model' actuel apr√®s trainer.train()) ---\nft_preds = generate_all(model, tokenizer, prompts, batch_size=4, max_new_tokens=64)\nft_em, ft_cer = score(ft_preds, refs)\n\nprint(f\"RAW -> Exact match: {raw_em:.3f} | CER: {raw_cer:.3f}\")\nprint(f\"FT  -> Exact match: {ft_em:.3f} | CER: {ft_cer:.3f}\")\nprint(f\"Œî   -> EM: {ft_em-raw_em:+.3f} | CER: {ft_cer-raw_cer:+.3f} \")\n\n# --- 3) Affiche quelques exemples pour sanity-check ---\nfor i in range(5):\n    print(\"\\nIN :\", inps[i])\n    print(\"REF:\", refs[i])\n    print(\"RAW:\", raw_preds[i] if i < len(raw_preds) else \"\")\n    print(\"FT :\", ft_preds[i])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-23T14:29:35.469250Z","iopub.execute_input":"2026-01-23T14:29:35.469706Z","iopub.status.idle":"2026-01-23T14:33:46.016972Z","shell.execute_reply.started":"2026-01-23T14:29:35.469656Z","shell.execute_reply":"2026-01-23T14:33:46.016044Z"}},"outputs":[{"name":"stdout","text":"==((====))==  Unsloth 2026.1.4: Fast Llama patching. Transformers: 4.56.2.\n   \\\\   /|    Tesla T4. Num GPUs = 2. Max memory: 14.741 GB. Platform: Linux.\nO^O/ \\_/ \\    Torch: 2.8.0+cu126. CUDA: 7.5. CUDA Toolkit: 12.6. Triton: 3.4.0\n\\        /    Bfloat16 = FALSE. FA [Xformers = None. FA2 = False]\n \"-____-\"     Free license: http://github.com/unslothai/unsloth\nUnsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\nDoctor-Shotgun/TinyLlama-1.1B-32k-Instruct does not have a padding token! Will use pad_token = <unk>.\nRAW -> Exact match: 0.002 | CER: 0.334\nFT  -> Exact match: 0.260 | CER: 0.109\nŒî   -> EM: +0.258 | CER: -0.226 \n\nIN : project looks to muelsnig ngeetic alternative\nREF: project looks to mulesing genetic alternative\nRAW: project looks to muelsnig ngeetic alternative\nFT : project looks to mulligan genetic alternative\n\nIN : chemical agents used during LrotWst at port ahgusra prixoj\nREF: chemical agents used during protest at port augusta prison\nRAW: chemical agents used during LrotWst at Port Ahgusra price\nFT : chemical agents used during port hughes portajopani\n\nIN : business hcmaber seeks budget infrastrcutuer boost\nREF: business chamber seeks budget infrastructure boost\nRAW: business hcmaber seeks budget infrastructure boost\nFT : business chamber seeks budget infrastructure boost\n\nIN : 3600 trips made to adrwni tip after cyconle\nREF: 3600 trips made to darwin tip after cyclone\nRAW: 3600 trips made to adrwni tip after cyconle\nFT : 3600 trips made to darwin tip after cyclone\n\nIN : go net3een brisye to lprn july 5\nREF: go between bridge to open july 5\nRAW: go net3een brisye to lprn july 5\nFT : go netten brisbane to return july 5\n","output_type":"stream"}],"execution_count":16},{"cell_type":"markdown","source":"## Conclusion & next steps\n\n- Fine-tuned a small LLM with LoRA (4-bit) for spelling correction\n- Improved EM / CER vs the base model : **EM: +0.258 | CER: -0.226**\n\n**Potential improvements**\n- Larger or cleaner dataset\n- Better decoding (beam search, temperature tuning)\n- More robust evaluation (multiple prompts, more test samples)\n","metadata":{}}]}